# ğŸ§  AI Task Planner Agent

A lightweight AI agent that **converts a task into a clear execution plan**, highlighting **steps, dependencies, and risks**, using a Large Language Model via **Ollama**.

This agent focuses purely on **planning and reasoning**, not execution.  
It is intentionally **simple**, easy to understand, and designed for learning how AI agents *think*.

---

## âœ¨ Features

- ğŸ§© Breaks tasks into clear, ordered steps  
- ğŸ”— Identifies dependencies between steps  
- âš ï¸ Highlights risky or unclear areas  
- ğŸ§  Focuses on reasoning, not execution  
- ğŸ”Œ Uses Ollama for local LLM inference  
- ğŸ“ Clean, minimal Python structure  

---

## ğŸ§  How It Works

1. A system prompt defines the agent as a **Task Planning Agent**
2. The user provides a task as input
3. The LLM generates:
   - An execution plan
   - Dependencies between steps
   - Risky or unclear areas
4. The agent **does not execute anything** â€” it only plans

---

## ğŸ“‚ Project Structure

```

ai-task-planner/
â”‚
â”œâ”€â”€ main.py               # Entry point
â”œâ”€â”€ task_planner.py       # Task planner agent logic
â”œâ”€â”€ ollama_client.py      # Ollama model wrapper
â”œâ”€â”€ planner_prompt.txt    # Prompt template used for planning
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

````

---

## âš™ï¸ Prerequisites

- Python **3.9+**
- **Ollama** installed (model invoked via Ollama CLI)
- Any Ollama-supported model (e.g. `llama3`, `mistral`)

ğŸ‘‰ Install Ollama: https://ollama.com/

---

## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/ai-task-planner.git
   cd ai-task-planner
````

2. Ensure Ollama is available:

   ```bash
   ollama serve
   ```

3. Run the task planner:

   ```bash
   python main.py
   ```

4. Enter a task when prompted.

---

## ğŸ§ª Example

**Input Task**

```
Build a local prompt evaluation tool using Ollama.
```

**Output**

```
Execution Plan:
1. Define evaluation criteria for prompt quality
2. Design the evaluator prompt
3. Set up the Ollama client
4. Implement the evaluation flow
5. Test with sample prompts
6. Document usage

Dependencies:
- Step 4 depends on steps 2 and 3
- Step 5 depends on step 4

Risky or Unclear Areas:
- Evaluation criteria may require refinement
- Model behavior may vary across runs
```

---

## ğŸ¯ Use Cases

* Planning AI or software projects
* Breaking vague tasks into actionable steps
* Identifying risks before execution
* Learning how LLMs reason about tasks
* Portfolio demo project for AI / GenAI roles

---

## ğŸ§  Design Philosophy

* One agent, one responsibility
* Prompt defines behavior, not code
* No execution or automation
* Focus on reasoning over```

ğŸ›£ï¸ Future Improvements

Execution readiness scoring (Go / No-Go)

Task complexity estimation

Planner confidence analysis

Prompt chaining (Clarifier â†’ Planner)

JSON structured output

CLI argument support